{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d905cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c209d922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mihirsaurkar/Documents/projects/ML-apps'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924a2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "66df55c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mihirsaurkar/Documents/projects/ML-apps/shakespeare\n"
     ]
    }
   ],
   "source": [
    "base_path = os.path.abspath(\"shakespeare\")\n",
    "\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "15f93bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = os.path.join(base_path,\"shakespeare.txt\")\n",
    "text = open(path_to_file,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c80edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text[40500:41800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fd3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3a33d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab) # will affect the last dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53506c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcf3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8530c311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H'] # encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9edec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab) # decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627cb7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d609fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0213b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a42094f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 120 # depends on the structure of text so model can learn the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "596a4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a826e0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5abe673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4fc48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d00108a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1,drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75b14d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbe710f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba22871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 09:21:13.922252: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "for input_txt,target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "    print(\"\\n\")\n",
    "    print(target_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f555b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f61931e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94ff6830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dfdcf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d1711cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba1308d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a4c6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77958057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72354f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2924b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU,Dense,Dropout,LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09504e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape = [batch_size,None]))\n",
    "    model.add(GRU(rnn_neurons, return_sequences = True, \n",
    "                  stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile('adam',loss=sparse_cat_loss)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a27d549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_m1(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape = [batch_size,None]))\n",
    "    model.add(GRU(rnn_neurons, \n",
    "                  activation='tanh',\n",
    "                  recurrent_activation=\"sigmoid\",\n",
    "                  return_sequences = True, \n",
    "                  stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GRU(rnn_neurons, activation='tanh',\n",
    "                   recurrent_activation=\"sigmoid\",\n",
    "                   return_sequences = True, \n",
    "                   stateful=True,\n",
    "                   recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile('adam',loss=sparse_cat_loss)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3788dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_m1(vocab_size=vocab_size,\n",
    "                     embed_dim=embed_dim,\n",
    "                     rnn_neurons=rnn_neurons,\n",
    "                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c86b127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (128, None, 64)           5376      \n",
      "                                                                 \n",
      " gru_10 (GRU)                (128, None, 1026)         3361176   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (128, None, 1026)         0         \n",
      "                                                                 \n",
      " gru_11 (GRU)                (128, None, 1026)         6322212   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (128, None, 84)           86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,775,032\n",
      "Trainable params: 9,775,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f63017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f4ed8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "351/351 [==============================] - 127s 357ms/step - loss: 2.9503\n",
      "Epoch 2/45\n",
      "351/351 [==============================] - 127s 359ms/step - loss: 2.5729\n",
      "Epoch 3/45\n",
      "351/351 [==============================] - 126s 357ms/step - loss: 2.5761\n",
      "Epoch 4/45\n",
      "351/351 [==============================] - 125s 355ms/step - loss: 2.5022\n",
      "Epoch 5/45\n",
      "351/351 [==============================] - 125s 355ms/step - loss: 2.5038\n",
      "Epoch 6/45\n",
      "351/351 [==============================] - 125s 355ms/step - loss: 2.4714\n",
      "Epoch 7/45\n",
      "351/351 [==============================] - 126s 356ms/step - loss: 2.4501\n",
      "Epoch 8/45\n",
      "351/351 [==============================] - 126s 358ms/step - loss: 2.4231\n",
      "Epoch 9/45\n",
      "351/351 [==============================] - 125s 356ms/step - loss: 2.4124\n",
      "Epoch 10/45\n",
      "351/351 [==============================] - 125s 355ms/step - loss: 2.4048\n",
      "Epoch 11/45\n",
      "351/351 [==============================] - 125s 355ms/step - loss: 2.4048\n",
      "Epoch 12/45\n",
      "351/351 [==============================] - 125s 355ms/step - loss: 2.3934\n",
      "Epoch 13/45\n",
      "351/351 [==============================] - 127s 360ms/step - loss: 2.4501\n",
      "Epoch 14/45\n",
      "351/351 [==============================] - 127s 362ms/step - loss: 2.4977\n",
      "Epoch 15/45\n",
      "351/351 [==============================] - 127s 360ms/step - loss: 2.4911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ddaef1f0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience = 3)\n",
    "model.fit(dataset,epochs=epochs,callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5d51f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c58b6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(base_path,\"shakespeare_gen.h5\")\n",
    "model_loaded  = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
    "model_loaded.load_weights(base_path+\"shakespeare_gen.h5\")\n",
    "model_loaded.build(tf.TensorShape([1,None,64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7333990",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = create_model_m1(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
    "model_trained.set_weights(model.get_weights())\n",
    "model_trained.build(tf.TensorShape([1,None,64]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0fa1e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (1, None, 64)             5376      \n",
      "                                                                 \n",
      " gru_12 (GRU)                (1, None, 1026)           3361176   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (1, None, 1026)           0         \n",
      "                                                                 \n",
      " gru_13 (GRU)                (1, None, 1026)           6322212   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (1, None, 84)             86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,775,032\n",
      "Trainable params: 9,775,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bad60298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (1, None, 64)             5376      \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (1, None, 1026)           3361176   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, None, 84)             86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85dc67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_seed, gen_size=500, temp=1.0):\n",
    "    num_generate = gen_size\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    input_eval = tf.expand_dims(input_eval,0)\n",
    "    text_generated  = []\n",
    "    temperatur = temp\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        \n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "        \n",
    "        predictions = predictions/temperatur\n",
    "        \n",
    "        predicted_id = tf.random.categorical(predictions, num_samples =1) [-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id],0)\n",
    "        \n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "        \n",
    "    return (start_seed + \"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5adc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeonar sf s sherssees rs or when.\n",
      "     Wr;\n",
      "\n",
      "  Thre we whe,       whaks. SHE all time together bide, success\n",
      "    To entertain assembling by this haste,\n",
      "    And fead to have your will bring her the gross extremes\n",
      "    Than you both in your compurries.\n",
      "  VIOLA. My brother, geter make excellent house.  \n",
      "  Francis, see you; but the fresh a song varlet plack block,\n",
      "    An army for a snatcast inwords than to draw enough.\n",
      "    I my will inslaughter to-morrow\n",
      "    Is took that fears with seeming theme.\n",
      "    Fear not our clothed;                            Exeunt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SCENE IV.\n",
      "Anous, and\n",
      "SICITITES house\n",
      "\n",
      "Enter an DUKE\n",
      " M] M', Bl.\n",
      "  faks, alks. FF sot kakat,\n",
      "\n",
      "  tat  k ntt an.\n",
      "    N at tan, mand jank?\n",
      "twe. nox dn codp.\n",
      " Mu mls I Fept, tamvn memell mil gn' thamlpvey nem, he tod liw bpy potlllnn. K.tUd peten ln  tonqen ty we Gfs eng. n thly fhet tho pteln, Tongit aml anf he ch pnelt ln. Jopnind nonbt,\n",
      "Sin parby that L. tppping mh rethank mong pmang mep!\n",
      " Fom Le llonf fott,\n",
      " ' Fening ?     noveven totaet do\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_trained,\"Romeo\", gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2b0be0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romeoning their fat lamening!  \n",
      "     sure?\n",
      "                                                      Exeunt the Threat\n",
      "\n",
      "Enter non this rite self-and sweet, and thy face be cross'd\n",
      "    With the mill of his own impy remorse applause\n",
      "    With ev'ry charrer tires. Nor how come you too late,  \n",
      "    Consorned in the life three up the thunder,\n",
      "    And in her pain is on you.  \n",
      "                                                         What has himself, in despite of a maid-\n",
      "    I'll stir out thee.\n",
      "  CLOWN. To sit obey e                  is not to begin\n",
      "      Well, go to your worviCes and gard no blood to sea\n",
      "    Thou canst not speak of comfort Kim.\n",
      "                              her heir to me,\n",
      "    As is unreigned English.\n",
      "  Pol. I hope no more accurs'd on his when says he'll usurp their way,  \n",
      "    And will offend their him. I  hot Buly Brutus, Desdemona?\n",
      "    Why dost thou stop my mother?  \n",
      "  WARWICK. Ay, to the maids here is but edded geam,\n",
      "    And what they should en Beh!\n",
      "                                \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_loaded,\"romeo\", gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf274e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10 (ml)",
   "language": "python",
   "name": "ml-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
