{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1246cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function to oobfuscate the store names and introduce impurities for the sake of this excercise\n",
    "# Scrapped or OCR results could be much more random and unpredictable.\n",
    "import string\n",
    "import random \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Using seen dictionary to generate all unique values\n",
    "# Main goal here is to ensure there is no cross category contamination\n",
    "# 1 input has single label, that model does not get confused\n",
    "seen = {}\n",
    "\n",
    "def gen_impurities(n,word):\n",
    "    for i in range(n):\n",
    "        index = random.randint(0,len(word)-1)\n",
    "        #print(f\"impute index - {index}\")\n",
    "\n",
    "        if index%2 == 0:\n",
    "            symbol = random.choice(string.punctuation)\n",
    "            #print(f\"Symbol = {symbol}\")\n",
    "            word = word[:index] + symbol + word[index:]\n",
    "\n",
    "        if index%7 == 0:\n",
    "            num = random.choice(string.digits)\n",
    "            #print(f\"Number = {num}\")\n",
    "            word = word[:index] + str(num) + word[index:]\n",
    "\n",
    "        if index%3 == 0:\n",
    "            word.replace(word[index],\"\")\n",
    "    return word\n",
    "\n",
    "def obfuscate(word):\n",
    "    n = int(len(word)*0.5)\n",
    "#     print(n)\n",
    "    iteration = random.randint(1,n)\n",
    "#     print(iteration)\n",
    "    label = word\n",
    "    for i in range(5):\n",
    "        imputed_word = gen_impurities(iteration,label)\n",
    "#         print(imputed_word)\n",
    "        if imputed_word not in seen:\n",
    "            seen[imputed_word] = 1\n",
    "            return imputed_word\n",
    "        seen[imputed_word] = seen[imputed_word]+1\n",
    "    return word\n",
    "            \n",
    "\n",
    "def gen_gibberish(min_l,max_l):\n",
    "    # initializing size of string\n",
    "    l = random.randint(min_l,max_l)\n",
    "    # using random.choices()\n",
    "    # generating random strings\n",
    "    res = ''.join(random.choices(string.ascii_uppercase +\n",
    "                                 string.punctuation +\n",
    "                                 string.digits, k=l))\n",
    "    while res not in seen:    \n",
    "        seen[res] = 1\n",
    "        return res\n",
    "    seen[res] = seen[res]+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e970c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take top 100 US retailers arbitarily chosen based on their annual reported Sales\n",
    "\n",
    "def read_data():\n",
    "    df = pd.read_csv(\"stores.csv\")\n",
    "    del df['empty']\n",
    "    df = df.set_index('no')\n",
    "    df.head()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484a1c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J9YU-Y/F~E%T(O'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test gibberish generator\n",
    "# we will set the min and max length of 5 to 20\n",
    "min_l = 5\n",
    "max_l = 20\n",
    "gen_gibberish(min_l,max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed32268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>$459.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>$217.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Costco Wholesale</td>\n",
       "      <td>$140.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>$140.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Kroger Co.</td>\n",
       "      <td>$136.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store  revenue\n",
       "no                           \n",
       "1            Walmart  $459.51\n",
       "2         Amazon.com  $217.79\n",
       "3   Costco Wholesale  $140.41\n",
       "4     The Home Depot  $140.06\n",
       "5     The Kroger Co.  $136.49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take top 100 US retailers arbitarily chosen based on their annual reported Sales\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"stores.csv\")\n",
    "del df['empty']\n",
    "df = df.set_index('no')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f494cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = list(df[\"store\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fbabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will muddle up the stores to simulate real world data capture where system might introduce impurites\n",
    "# the function will generate n number of instances for jumbled data\n",
    "\n",
    "# n indicates number of obfuscated records\n",
    "# instance_count is the number of observation per class\n",
    "\n",
    "def get_obfuscated_stores(stores,n):\n",
    "    \"\"\"\n",
    "        This functions takes the stores list\n",
    "        Repeats it n times\n",
    "        calls teh obfuscate function to generate dirty names\n",
    "    \"\"\"\n",
    "    obfuscate_stores = stores * n\n",
    "    obfuscate_stores.sort()\n",
    "    df_obfuscated = pd.DataFrame({\"stores\": obfuscate_stores})\n",
    "    df_obfuscated['bad_names'] = df_obfuscated[\"stores\"].apply(lambda x: obfuscate(x) )\n",
    "    return df_obfuscated\n",
    "    \n",
    "def get_catch_gibberish(instance_count,min_l,max_l):\n",
    "    others = ['Other'] * instance_count\n",
    "    df_other = pd.DataFrame({'stores':others})\n",
    "    df_other['bad_names'] = df_other['stores'].apply(lambda x : gen_gibberish(min_l,max_l)) \n",
    "    return df_other\n",
    "\n",
    "# the training set will also have good captures where store name was interpreted correctly\n",
    "# for this purpose the we are creagin 10% bad captures\n",
    "\n",
    "def get_good_names(stores,n):\n",
    "    good_captures = stores*  n\n",
    "    df_good_captures = pd.DataFrame({'stores':good_captures})\n",
    "    df_good_captures['bad_names'] = df_good_captures[\"stores\"]\n",
    "    return df_good_captures\n",
    "\n",
    "def get_data(impute_n,instance,min_l,max_l): \n",
    "    n = impute_n\n",
    "    instance_count = instance\n",
    "    min_l = min_l\n",
    "    max_l = max_l\n",
    "\n",
    "    df_obfuscated = get_obfuscated_stores(stores,n)\n",
    "    df_other = get_catch_gibberish(instance_count,min_l,max_l)\n",
    "    df_good_captures = repeat_good_names(stores,n,instance_count)\n",
    "    df = pd.concat([df_obfuscated,df_good_captures,df_other])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d8cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(split_ratio,impute_ratio,instance,min_l,max_l):\n",
    "    test_size = (instance*split_ratio)\n",
    "    train_size = (instance*(1-split_ratio))\n",
    "    print(f\"test_size = {test_size} & train_size = {train_size} & split = {split_ratio}\")\n",
    "    test_impute_n = int(test_size*impute_ratio)\n",
    "    test_good_n = int(test_size - test_impute_n)\n",
    "    print(f\"test impute = {test_impute_n} & instances = {test_good_n}\")\n",
    "    df = read_data()\n",
    "    stores = list(df[\"store\"])\n",
    "    # get imputed\n",
    "    df_obfuscated = get_obfuscated_stores(stores,test_impute_n)\n",
    "    # get good names\n",
    "    df_good_names = get_good_names(stores, test_good_n)\n",
    "    # get others \n",
    "    df_other = get_catch_gibberish(test_impute_n+test_good_n,min_l,max_l)\n",
    "    df_test = pd.concat([df_obfuscated,df_good_names,df_other])\n",
    "    \n",
    "    del df_obfuscated,df_good_names,df_other\n",
    "    train_impute_n = int(train_size*impute_ratio)\n",
    "    train_good_n = int(train_size - train_impute_n)\n",
    "    # get imputed\n",
    "    df_obfuscated = get_obfuscated_stores(stores,train_impute_n)\n",
    "    # get good names\n",
    "    df_good_names = get_good_names(stores, train_good_n)\n",
    "    # get others \n",
    "    df_other = get_catch_gibberish(train_impute_n+train_good_n,min_l,max_l)\n",
    "    \n",
    "    df_train = pd.concat([df_obfuscated,df_good_names,df_other])\n",
    "    \n",
    "    del df_obfuscated,df_good_names,df_other\n",
    "    return df_train, df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9378043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size = 10.0 & train_size = 40.0 & split = 0.2\n",
      "test impute = 5 & instances = 5\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.2\n",
    "impute_ratio = 0.5\n",
    "instances = 50\n",
    "min_l = 5\n",
    "max_l = 20\n",
    "\n",
    "df_train, df_test = get_train_test_data(split_ratio,\n",
    "                                        impute_ratio,\n",
    "                                        instances,\n",
    "                                        min_l,\n",
    "                                        max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410918b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "def get_train_test_split(df_train,df_test,one_hot_encode_labels=False):\n",
    "    X_train = df_train[\"bad_names\"].values\n",
    "    y_train = df_train[\"stores\"].values\n",
    "    X_test  = df_test[\"bad_names\"].values\n",
    "    y_test  = df_test[\"stores\"].values\n",
    "    \n",
    "    if one_hot_encode_labels:\n",
    "        df_labels = pd.concat([df_train['stores'],df_test['stores']])\n",
    "        print(f\"Labels = {df_labels.shape})\")\n",
    "        lables = pd.get_dummies(df_labels)\n",
    "        lookup = list(lables.columns)\n",
    "        print(len(lookup))\n",
    "        del df_labels\n",
    "        y_test_labels = pd.get_dummies(y_test)\n",
    "        y_test_encoded = y_test_labels.astype('float32').values\n",
    "        y_train_labels = pd.get_dummies(y_train)\n",
    "        y_train_encoded = y_train_labels.astype('float32').values\n",
    "        return X_train,y_train_encoded,X_test,y_test_encoded, lookup\n",
    "    else:\n",
    "        return X_train, y_train, X_test, y_test, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b00dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train, X_test, y_test, lable_lookup = get_train_test_split(df_train,\n",
    "                                                                      df_test,\n",
    "                                                                      one_hot_encode_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(list(X_train))\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82db9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' !' ' \"' ' #' ... '~|' '~}' '~~']\n",
      "3088\n"
     ]
    }
   ],
   "source": [
    "## tf - idf\n",
    "## some more robust embeddings are needed.\n",
    "## Creting character level TF-EDF encoder/vectorizer to convert strings to consistent length vectors\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = X_train\n",
    "vectorizer = TfidfVectorizer(analyzer='char',strip_accents =\"ascii\" , ngram_range=(2,2)).fit(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(len(vectorizer.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1cb0061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of train - (4040, 3088) and len = 4040\n",
      " shage of test - (1010, 3088) and len = 1010\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"7-&E+l#'/-ev&en as\"]\n",
    "X_train_vector= vectorizer.transform(X_train).toarray()\n",
    "X_test_vector = vectorizer.transform(X_test).toarray()\n",
    "print(f\" shape of train - {X_train_vector.shape} and len = {len(X_train_vector)}\")\n",
    "print(f\" shage of test - {X_test_vector.shape} and len = {len(X_test_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daafcd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&lt;function correlation at 0x16887c790&gt;, n_jobs=10,\n",
       "                     n_neighbors=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&lt;function correlation at 0x16887c790&gt;, n_jobs=10,\n",
       "                     n_neighbors=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric=<function correlation at 0x16887c790>, n_jobs=10,\n",
       "                     n_neighbors=20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.spatial import distance      \n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=20,n_jobs=10, metric = distance.correlation,)\n",
    "classifier.fit(X_train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2773a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier(w:list,vectorizer,classifier):\n",
    "    w_vector = vectorizer.transform(w).toarray()\n",
    "    pred = classifier.predict(w_vector)\n",
    "    conf = classifier.predict_proba(w_vector)    \n",
    "    return pred,conf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269dc212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6506245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Target', 'Target', 'Other', 'Gap', '7-Eleven', 'Ace Hardware'],\n",
       "       dtype=object),\n",
       " array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.05, 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.05,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n",
       "         0.05, 0.05, 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.05, 0.  , 0.05, 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.05, 0.  , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.1 , 0.  , 0.  , 0.05, 0.05, 0.  , 0.  , 0.  , 0.05, 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  ],\n",
       "        [0.9 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.05, 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.95, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  ]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stores = [\"Targe1\", \n",
    "                \"Larget\", \n",
    "                '!a7g3T',\n",
    "                \"'7argay'\",\n",
    "                \"7- 11\",\n",
    "                \"Ac3 Hw\"]\n",
    "my_classifier(test_stores\n",
    "              ,vectorizer,classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_test)\n",
    "## takes a while\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(len(X_test))\n",
    "y_predicted = []\n",
    "for i in range(len(X_test)):\n",
    "    pred = my_classifier([X_test[i]],vectorizer,classifier)\n",
    "    print(f\" {i}] Input - {X_test[i]} predicted - {pred[0]} \")\n",
    "    y_predicted.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ece9815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = pd.DataFrame({'test_names':X_test,'actual':y_test})\n",
    "conf_mat[\"predicted\"] = conf_mat[\"test_names\"].apply(lambda x : my_classifier([x],vectorizer,classifier)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "568e7cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_names</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/*7-Ele=ven</td>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>7-Eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7-El..even</td>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>7-Eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>7-Eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-Elev[e1n</td>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>7-Eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-El|even</td>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>7-Eleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT&amp;T@ Wireles]s</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AT&amp;T W-irele_ss</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT&amp;T Wirel,e~ss</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AT$&amp;T ?W#ireless</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AT&amp;T` !(Wirele3,ss</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "      <td>AT&amp;T Wireless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_names         actual      predicted\n",
       "0        1/*7-Ele=ven       7-Eleven       7-Eleven\n",
       "1          7-El..even       7-Eleven       7-Eleven\n",
       "2            7-Eleven       7-Eleven       7-Eleven\n",
       "3          7-Elev[e1n       7-Eleven       7-Eleven\n",
       "4           7-El|even       7-Eleven       7-Eleven\n",
       "5     AT&T@ Wireles]s  AT&T Wireless  AT&T Wireless\n",
       "6     AT&T W-irele_ss  AT&T Wireless  AT&T Wireless\n",
       "7     AT&T Wirel,e~ss  AT&T Wireless  AT&T Wireless\n",
       "8    AT$&T ?W#ireless  AT&T Wireless  AT&T Wireless\n",
       "9  AT&T` !(Wirele3,ss  AT&T Wireless  AT&T Wireless"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f326c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conf_mat[\"predicted\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1328c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# result = confusion_matrix(y_test, y_predicted)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(result)\n",
    "# result1 = classification_report(y_test, y_predicted)\n",
    "# print(\"Classification Report:\",)\n",
    "# print (result1)\n",
    "# result2 = accuracy_score(y_test,y_predicted)\n",
    "# print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beb8ac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10  0  0 ...  0  0  0]\n",
      " [ 0 10  0 ...  0  0  0]\n",
      " [ 0  0 10 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 10  0  0]\n",
      " [ 0  0  0 ...  0 10  0]\n",
      " [ 0  0  0 ...  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(conf_mat['actual'].values,conf_mat['predicted'].values)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de0f0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                           7-Eleven       0.91      1.00      0.95        10\n",
      "                      AT&T Wireless       1.00      1.00      1.00        10\n",
      "                    AVB Brandsource       1.00      1.00      1.00        10\n",
      "                     Academy Sports       1.00      1.00      1.00        10\n",
      "                       Ace Hardware       1.00      1.00      1.00        10\n",
      "                       Advance Auto       1.00      1.00      1.00        10\n",
      "               Albertsons Companies       1.00      1.00      1.00        10\n",
      "                               Aldi       0.91      1.00      0.95        10\n",
      "           Alimentation Couche-Tard       1.00      1.00      1.00        10\n",
      "                         Amazon.com       1.00      1.00      1.00        10\n",
      "          American Eagle Outfitters       1.00      1.00      1.00        10\n",
      "              Apple Stores / iTunes       1.00      1.00      1.00        10\n",
      "Army and Air Force Exchange Service       1.00      1.00      1.00        10\n",
      "                           AutoZone       1.00      1.00      1.00        10\n",
      "                BJ's Wholesale Club       1.00      1.00      1.00        10\n",
      "                     Barnes & Noble       0.91      1.00      0.95        10\n",
      "                           Bass Pro       1.00      1.00      1.00        10\n",
      "                  Bath & Body Works       1.00      1.00      1.00        10\n",
      "                  Bed Bath & Beyond       1.00      1.00      1.00        10\n",
      "                           Best Buy       1.00      1.00      1.00        10\n",
      "                           Big Lots       1.00      1.00      1.00        10\n",
      "                         Burlington       1.00      1.00      1.00        10\n",
      "             CVS Health Corporation       1.00      1.00      1.00        10\n",
      "                      Camping World       1.00      1.00      1.00        10\n",
      "              Casey's General Store       0.91      1.00      0.95        10\n",
      "                          Chewy.com       1.00      1.00      1.00        10\n",
      "                   Costco Wholesale       1.00      1.00      1.00        10\n",
      "          Defense Commissary Agency       1.00      1.00      1.00        10\n",
      "                  Dell Technologies       1.00      1.00      1.00        10\n",
      "              Dick's Sporting Goods       1.00      1.00      1.00        10\n",
      "                          Dillard's       1.00      1.00      1.00        10\n",
      "                      Discount Tire       1.00      1.00      1.00        10\n",
      "                     Dollar General       1.00      1.00      1.00        10\n",
      "                        Dollar Tree       1.00      1.00      1.00        10\n",
      "            Exxon Mobil Corporation       1.00      1.00      1.00        10\n",
      "                        Foot Locker       1.00      1.00      1.00        10\n",
      "                                Gap       1.00      1.00      1.00        10\n",
      "                        Giant Eagle       1.00      1.00      1.00        10\n",
      "                              Golub       1.00      1.00      1.00        10\n",
      "             Good Neighbor Pharmacy       1.00      1.00      1.00        10\n",
      "                  H.E. Butt Grocery       1.00      1.00      1.00        10\n",
      "               Harbor Freight Tools       1.00      1.00      1.00        10\n",
      "                Health Mart Systems       1.00      1.00      1.00        10\n",
      "                 Hobby Lobby Stores       1.00      1.00      1.00        10\n",
      "                       Hudson's Bay       1.00      1.00      1.00        10\n",
      "                             Hy Vee       1.00      1.00      1.00        10\n",
      "        Ikea North America Services       1.00      1.00      1.00        10\n",
      "                             Ingles       1.00      1.00      1.00        10\n",
      "                J.C. Penney Company       1.00      1.00      1.00        10\n",
      "                             Kohl's       1.00      1.00      1.00        10\n",
      "                   Lowe's Companies       1.00      1.00      1.00        10\n",
      "                          Lululemon       1.00      1.00      1.00        10\n",
      "                             Macy's       1.00      1.00      1.00        10\n",
      "                             Meijer       1.00      1.00      1.00        10\n",
      "                            Menards       1.00      1.00      1.00        10\n",
      "                    Michaels Stores       1.00      1.00      1.00        10\n",
      "                        My Demoulas       1.00      1.00      1.00        10\n",
      "                          Nordstrom       1.00      1.00      1.00        10\n",
      "                       Office Depot       1.00      1.00      1.00        10\n",
      "                              Other       1.00      0.10      0.18        10\n",
      "                O’Reilly Auto Parts       1.00      1.00      1.00        10\n",
      "                           PetSmart       1.00      1.00      1.00        10\n",
      "                              Petco       1.00      1.00      1.00        10\n",
      "                      Piggly Wiggly       1.00      1.00      1.00        10\n",
      "               Publix Super Markets       1.00      1.00      1.00        10\n",
      "                      Qurate Retail       1.00      1.00      1.00        10\n",
      "                                 RH       0.71      1.00      0.83        10\n",
      "                           Rite Aid       1.00      1.00      1.00        10\n",
      "                        Ross Stores       1.00      1.00      1.00        10\n",
      "           Royal Ahold Delhaize USA       1.00      1.00      1.00        10\n",
      "                          Save Mart       1.00      1.00      1.00        10\n",
      "                         Save-A-Lot       1.00      1.00      1.00        10\n",
      "                     Sephora (LVMH)       1.00      1.00      1.00        10\n",
      "                  Shell Oil Company       1.00      1.00      1.00        10\n",
      "                   Sherwin-Williams       1.00      1.00      1.00        10\n",
      "                    Signet Jewelers       1.00      1.00      1.00        10\n",
      "                      Smart & Final       1.00      1.00      1.00        10\n",
      "               Southeastern Grocers       1.00      1.00      1.00        10\n",
      "             Sprouts Farmers Market       1.00      1.00      1.00        10\n",
      "                            Staples       1.00      1.00      1.00        10\n",
      "               Stater Bros Holdings       1.00      1.00      1.00        10\n",
      "                      TJX Companies       1.00      1.00      1.00        10\n",
      "                           Tapestry       1.00      1.00      1.00        10\n",
      "                             Target       1.00      1.00      1.00        10\n",
      "                     The Home Depot       1.00      1.00      1.00        10\n",
      "                     The Kroger Co.       1.00      1.00      1.00        10\n",
      "                  Total Wine & More       1.00      1.00      1.00        10\n",
      "                 Tractor Supply Co.       1.00      1.00      1.00        10\n",
      "                     True Value Co.       1.00      1.00      1.00        10\n",
      "                        Ulta Beauty       1.00      1.00      1.00        10\n",
      "                   Urban Outfitters       1.00      1.00      1.00        10\n",
      "                   Verizon Wireless       1.00      1.00      1.00        10\n",
      "                  Victoria's Secret       1.00      1.00      1.00        10\n",
      "                Wakefern / ShopRite       1.00      1.00      1.00        10\n",
      "           Walgreens Boots Alliance       1.00      1.00      1.00        10\n",
      "                            Walmart       0.91      1.00      0.95        10\n",
      "                            Wayfair       1.00      1.00      1.00        10\n",
      "                Wegmans Food Market       1.00      1.00      1.00        10\n",
      "                       Weis Markets       1.00      1.00      1.00        10\n",
      "                    Williams-Sonoma       1.00      1.00      1.00        10\n",
      "                        WinCo Foods       1.00      1.00      1.00        10\n",
      "\n",
      "                           accuracy                           0.99      1010\n",
      "                          macro avg       0.99      0.99      0.99      1010\n",
      "                       weighted avg       0.99      0.99      0.99      1010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = classification_report(conf_mat['actual'].values,conf_mat['predicted'].values)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc31c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9910891089108911\n"
     ]
    }
   ],
   "source": [
    "result2 = accuracy_score(conf_mat['actual'].values,conf_mat['predicted'].values)\n",
    "print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2caee9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ikea North America Services'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier(['7a G3 7'],vectorizer,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e7f89a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['True Value Co.'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier(['12321ueiajsidams'],vectorizer,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59970c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Target'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier(['Target'],vectorizer,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d48d04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Target'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier(['T1argea214'],vectorizer,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d450f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10 (ml)",
   "language": "python",
   "name": "ml-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
